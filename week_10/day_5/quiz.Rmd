---
title: "R Notebook"
output: html_notebook
---

Quiz 

1) I want to predict how well 6 year-olds are going to do in their final school exams. Using the following variables am I likely under-fitting, fitting well or over-fitting? Postcode, gender, reading level, score in maths test, date of birth, family income.

Most likely over-fitting, since it's only 6 year olds date of birth shouldn't be in the model

2) If I have two models, one with an AIC score of 34,902 and the other with an AIC score of 33,559 which model should I use?

AIC is a score of error so the 2nd model with a lower score should be used

3) I have two models, the first with: r-squared: 0.44, adjusted r-squared: 0.43. The second with: r-squared: 0.47, adjusted r-squared: 0.41. Which one should I use?

The first model with higher adjusted r-squared should be used since it includes a penalty for extra variables in the model

4) I have a model with the following errors: RMSE error on test set: 10.3, RMSE error on training data: 10.4. Do you think this model is over-fitting?

No, the RMSE is similar for test and training data.

5) How does k-fold validation work?

By creating new models with a different split for test and train each time and finding the best model from the different parameters.

6) What is a validation set? When do you need one?

Similar to a test set although it is used to check the model isn't overfit to the test set. If you have enough data then it's good practice to have one.

7) Describe how backwards selection works.

By including all possible variables in the model and removing the one with least impact on the model each time so you can remove the complication without losing prediction accuracy.

8) Describe how best subset selection works.

Best subset works by finding the best set of variables to include for each additional variable e.g 2, 3, 4 variables.



