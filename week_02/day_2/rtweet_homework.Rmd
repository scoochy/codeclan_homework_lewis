---
title: "R Notebook"
output: html_notebook
---

```{r}
library(tidyverse)
library(stringr)
```

```{r}
info <- read.csv("data/code_clan_info.csv")
tweets <- read.csv("data/code_clan_tweets.csv")
```

Q1:

```{r}
names(tweets)
```

```{r}
dim(tweets)
```
Q2:

```{r}
tweets %>% 
  filter(is_quote == FALSE) %>% 
  summarise(total_fav = sum(favorite_count))
  
```

Q3:

```{r}
tweets %>% 
  filter(is_quote == FALSE) %>%
  group_by(source) %>% 
  summarise(average_rt_platform = mean(retweet_count))
```

Q4:

```{r}
coalesced_tweets <- tweets %>% 
  mutate(media_type = coalesce(media_type, "text")) %>% 
  group_by(media_type) %>% 
  summarise(total_fav = sum(favorite_count))
  

coalesced_tweets
```

Q5:

```{r}
tweets %>% 
  select(display_text_width) %>% 
  summarise(mean(display_text_width))

tweets %>% 
  mutate(count_str_length = str_length(text)) %>% 
  summarise(mean(count_str_length))
  
```


Q6:

```{r}
tweets_info <- left_join(tweets, info, by = "tweet_id")
```

Q7:

```{r}
(codeclan_hashtags <- tweets_info %>% 
  select(tweet_id, hashtags) %>% 
  mutate(hashtags = str_to_lower(hashtags)))
  filter(!is.na(hashtags)) %>% 

codeclan_hashtags
  
```

Q8:


```{r}
pattern <- "c\\("

occurences <- codeclan_hashtags %>% 
  select(hashtags) %>% 
  mutate(first_letters = substr(hashtags, 1, 2)) %>% 
  filter(str_detect(first_letters, pattern))
  
```

Q9:

```{r}
edin_pattern <- "(?i)edinburgh"

mentions <- tweets %>% 
  select(text) %>% 
  str_extract_all(edin_pattern)
  
mentions
```
Q10:

```{r}
user_pattern <- "@[a-zA-Z0-9_]+"

usernames <- tweets %>% 
  select(text) %>% 
  str_extract_all(user_pattern) %>% 
  flatten_chr()

usernames


tweets %>%
  select(text) %>%
  mutate(user_tweeeted = str_extract_all(text, "@[A-z0-9_]+")) %>%
  unnest(cols = c(user_tweeeted)) %>%
  group_by(user_tweeeted) %>%
  summarise(count = n()) %>%
  arrange(desc(count))
```


